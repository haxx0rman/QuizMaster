"""
Integration module that demonstrates the complete Ragas-inspired QuizMaster system.

This module shows how all components work together:
- Knowledge extraction with LightRAG
- Advanced scenario generation with personas
- Sophisticated question generation
- Integration with qBank for spaced repetition
"""

import asyncio
import logging
from typing import List, Optional, Dict, Any

from .knowledge_extractor import KnowledgeExtractor
from .question_generator import HumanLearningQuestionGenerator
from .scenario_generator import AdvancedScenarioGenerator, PersonaProfile
from ..models.knowledge_graph import KnowledgeGraph
from ..models.question import Question, DifficultyLevel
from .config import get_config

logger = logging.getLogger(__name__)


class QuizMasterPipeline:
    """
    Complete pipeline integrating all QuizMaster components.
    
    This class demonstrates the full Ragas-inspired workflow:
    1. Extract knowledge from documents using LightRAG
    2. Generate diverse scenarios with persona-based approach
    3. Create educational questions optimized for human learning
    4. Integrate with qBank for spaced repetition
    """
    
    def __init__(
        self,
        config: Optional[Any] = None,
        personas: Optional[List[PersonaProfile]] = None,
        working_dir: Optional[str] = None
    ):
        """Initialize the complete pipeline."""
        self.config = config or get_config()
        
        # Initialize knowledge extractor
        self.knowledge_extractor = KnowledgeExtractor(
            openai_api_key=self.config.llm.openai_api_key,
            openai_base_url=self.config.llm.openai_base_url,
            llm_model=self.config.llm.llm_model,
            embedding_model=self.config.llm.embedding_model,
            working_dir=working_dir
        )
        
        # Initialize question generator with advanced scenarios
        self.question_generator = HumanLearningQuestionGenerator(
            config=self.config,
            personas=personas
        )
        
        # Initialize scenario generator
        self.scenario_generator = AdvancedScenarioGenerator(personas)
        
        logger.info("QuizMaster pipeline initialized with Ragas-inspired methodology")
    
    async def process_documents_to_questions(
        self,
        documents: List[str],
        num_questions: int = 20,
        topic: str = "General Knowledge",
        learning_objectives: Optional[List[str]] = None,
        difficulty_distribution: Optional[Dict[DifficultyLevel, float]] = None
    ) -> Dict[str, Any]:
        """
        Complete pipeline: documents â†’ knowledge graph â†’ scenarios â†’ questions.
        
        Args:
            documents: List of document texts to process
            num_questions: Number of questions to generate
            topic: Main topic/subject area
            learning_objectives: Specific learning goals
            difficulty_distribution: Distribution of difficulty levels
            
        Returns:
            Dictionary containing all pipeline outputs
        """
        logger.info(f"Starting complete pipeline for {len(documents)} documents")
        
        # Step 1: Extract knowledge graph
        logger.info("Step 1: Extracting knowledge graph from documents...")
        knowledge_graph = await self.knowledge_extractor.extract_knowledge_from_documents(
            documents,
            source_ids=[f"doc_{i}" for i in range(len(documents))]
        )
        
        logger.info(f"Extracted knowledge graph: {knowledge_graph.node_count} nodes, {knowledge_graph.edge_count} edges")
        
        # Step 2: Generate advanced scenarios
        logger.info("Step 2: Generating diverse scenarios with personas...")
        scenarios = self.scenario_generator.generate_diverse_scenarios(
            knowledge_graph=knowledge_graph,
            num_scenarios=num_questions
        )
        
        logger.info(f"Generated {len(scenarios)} diverse scenarios")
        
        # Step 3: Generate questions from scenarios
        logger.info("Step 3: Generating educational questions...")
        questions = await self.question_generator.generate_questions_from_knowledge_graph(
            knowledge_graph=knowledge_graph,
            num_questions=num_questions,
            topic=topic,
            learning_objectives=learning_objectives
        )
        
        logger.info(f"Generated {len(questions)} questions")
        
        # Step 4: Analyze and categorize results
        results = self._analyze_pipeline_results(
            knowledge_graph=knowledge_graph,
            scenarios=scenarios,
            questions=questions,
            topic=topic
        )
        
        return results
    
    def _analyze_pipeline_results(
        self,
        knowledge_graph: KnowledgeGraph,
        scenarios: List[Any],
        questions: List[Question],
        topic: str
    ) -> Dict[str, Any]:
        """Analyze and categorize pipeline results."""
        
        # Analyze question distribution
        difficulty_distribution = {}
        complexity_distribution = {}
        persona_distribution = {}
        
        for question in questions:
            # Difficulty analysis
            diff = question.difficulty.value if question.difficulty else "unknown"
            difficulty_distribution[diff] = difficulty_distribution.get(diff, 0) + 1
            
            # Extract metadata if available (Questions don't have metadata by default, so we'll use tags)
            tags = question.tags or set()
            
            # For complexity analysis, we'll check if we can derive it from tags or other attributes
            complexity = "unknown"
            if any("single_hop" in str(tag) for tag in tags):
                complexity = "single_hop"
            elif any("multi_hop" in str(tag) for tag in tags):
                complexity = "multi_hop"
            complexity_distribution[complexity] = complexity_distribution.get(complexity, 0) + 1
            
            # For persona analysis, check question ID or other identifiers
            persona = "general"  # Default since questions don't have persona metadata by default
            persona_distribution[persona] = persona_distribution.get(persona, 0) + 1
        
        # Analyze scenarios
        scenario_types = {}
        for scenario in scenarios:
            try:
                complexity_attr = getattr(scenario, 'complexity', 'unknown')
                # Convert to string representation
                scenario_type = str(complexity_attr)
                scenario_types[scenario_type] = scenario_types.get(scenario_type, 0) + 1
            except Exception:
                # Fallback for any scenario type issues
                scenario_types['unknown'] = scenario_types.get('unknown', 0) + 1
        
        return {
            "pipeline_summary": {
                "total_documents_processed": len(knowledge_graph.metadata.get("source_ids", [])),
                "knowledge_graph_nodes": knowledge_graph.node_count,
                "knowledge_graph_edges": knowledge_graph.edge_count,
                "scenarios_generated": len(scenarios),
                "questions_generated": len(questions),
                "topic": topic
            },
            "knowledge_graph": {
                "nodes": knowledge_graph.node_count,
                "edges": knowledge_graph.edge_count,
                "metadata": knowledge_graph.metadata
            },
            "question_analysis": {
                "difficulty_distribution": difficulty_distribution,
                "complexity_distribution": complexity_distribution,
                "persona_distribution": persona_distribution,
                "total_questions": len(questions)
            },
            "scenario_analysis": {
                "scenario_types": scenario_types,
                "total_scenarios": len(scenarios)
            },
            "questions": [q.to_dict() for q in questions],
            "ragas_methodology_features": {
                "knowledge_graph_based": True,
                "scenario_driven": True,
                "persona_aware": True,
                "multi_hop_reasoning": True,
                "educational_optimization": True,
                "complexity_distribution": True
            }
        }
    
    async def demonstrate_ragas_features(self) -> Dict[str, Any]:
        """
        Demonstrate key Ragas-inspired features with sample data.
        
        Returns:
            Dictionary showing all the advanced features implemented
        """
        logger.info("Demonstrating Ragas-inspired features...")
        
        # Sample documents for demonstration
        sample_documents = [
            """
            Machine Learning is a subset of artificial intelligence (AI) that enables computers to learn 
            and make decisions from data without being explicitly programmed. The field encompasses various 
            algorithms including supervised learning, unsupervised learning, and reinforcement learning.
            
            Neural networks are a key component of deep learning, which is a subset of machine learning. 
            These networks are inspired by biological neural networks and consist of interconnected nodes 
            that process information in layers.
            """,
            """
            Deep Learning has revolutionized many fields including computer vision, natural language 
            processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly 
            effective for image processing tasks, while Recurrent Neural Networks (RNNs) excel at 
            sequential data processing.
            
            The training process involves optimization algorithms like gradient descent to minimize 
            loss functions and improve model performance. Regularization techniques help prevent 
            overfitting and improve generalization.
            """,
            """
            Artificial Intelligence ethics and responsible AI development have become increasingly important 
            as AI systems are deployed in critical applications. Issues include bias in algorithms, 
            transparency, accountability, and the societal impact of AI decisions.
            
            Explainable AI (XAI) aims to make AI systems more interpretable and trustworthy by providing 
            insights into how decisions are made. This is crucial for applications in healthcare, finance, 
            and legal systems where transparency is essential.
            """
        ]
        
        # Run complete pipeline
        results = await self.process_documents_to_questions(
            documents=sample_documents,
            num_questions=15,
            topic="Artificial Intelligence and Machine Learning",
            learning_objectives=[
                "Understand the relationship between AI, ML, and Deep Learning",
                "Recognize different types of neural networks and their applications",
                "Appreciate the importance of AI ethics and explainability"
            ]
        )
        
        # Add demonstration-specific analysis
        results["demonstration_highlights"] = {
            "ragas_inspired_features": [
                "Knowledge graph construction from documents",
                "Multi-hop reasoning across connected concepts",
                "Persona-based question generation",
                "Scenario-driven approach to test creation",
                "Educational optimization for human learning",
                "Diverse complexity levels (single-hop, multi-hop, abstract)",
                "Integration-ready for spaced repetition systems"
            ],
            "educational_benefits": [
                "Questions adapted to different learner personas",
                "Progressive difficulty levels for scaffolded learning",
                "Conceptual and factual question types",
                "Cross-document reasoning capabilities",
                "Learning objective alignment"
            ],
            "technical_innovations": [
                "LightRAG integration for knowledge extraction",
                "Advanced scenario generation with graph traversal",
                "Persona-aware question synthesis",
                "Quality validation and scoring",
                "Comprehensive configuration management"
            ]
        }
        
        return results
    
    def get_pipeline_status(self) -> Dict[str, Any]:
        """Get current pipeline status and configuration."""
        return {
            "pipeline_components": {
                "knowledge_extractor": "LightRAG-based knowledge graph extraction",
                "scenario_generator": "Advanced Ragas-inspired scenario generation",
                "question_generator": "Human learning optimized question creation",
                "configuration": "Comprehensive environment-based configuration"
            },
            "capabilities": {
                "single_hop_specific": "Factual questions from single sources",
                "single_hop_abstract": "Conceptual questions requiring interpretation",
                "multi_hop_specific": "Questions connecting multiple sources",
                "multi_hop_abstract": "Complex reasoning across knowledge domains",
                "persona_adaptation": "Questions adapted to learner types",
                "difficulty_progression": "Scaffolded learning progression"
            },
            "integration_ready": {
                "qbank_compatibility": "Ready for spaced repetition integration",
                "lightrag_integration": "Full knowledge graph capabilities",
                "openai_api": "LLM-powered question generation",
                "configuration_management": "Comprehensive .env support"
            }
        }
    
    def cleanup(self):
        """Clean up pipeline resources."""
        if hasattr(self.knowledge_extractor, 'cleanup'):
            self.knowledge_extractor.cleanup()
        logger.info("Pipeline cleanup completed")


# Convenience function for quick demonstration
async def demonstrate_complete_system():
    """Quick demonstration of the complete QuizMaster system."""
    pipeline = QuizMasterPipeline()
    
    try:
        results = await pipeline.demonstrate_ragas_features()
        
        print("ðŸŽ“ QuizMaster: Ragas-Inspired Question Generation System")
        print("=" * 60)
        print(f"ðŸ“Š Generated {results['pipeline_summary']['questions_generated']} questions")
        print(f"ðŸ§  Knowledge Graph: {results['knowledge_graph']['nodes']} nodes, {results['knowledge_graph']['edges']} edges")
        print(f"ðŸŽ­ Scenarios: {results['scenario_analysis']['total_scenarios']} diverse scenarios")
        print("\nðŸ”¬ Ragas-Inspired Features:")
        for feature in results['demonstration_highlights']['ragas_inspired_features']:
            print(f"  âœ… {feature}")
        
        print("\nðŸ“ˆ Question Distribution:")
        for difficulty, count in results['question_analysis']['difficulty_distribution'].items():
            print(f"  {difficulty.title()}: {count} questions")
        
        return results
        
    finally:
        pipeline.cleanup()


if __name__ == "__main__":
    # Run demonstration
    asyncio.run(demonstrate_complete_system())
